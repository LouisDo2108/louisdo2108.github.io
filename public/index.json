[{"content":"Brain tumor segmentation is a critical task in medical image analysis, and the BraTS (Brain Tumor Segmentation) challenge dataset is one of the most widely used benchmarks in the field. However, getting started with brain imaging can be intimidating, especially if you\u0026rsquo;re not familiar with the complex medical jargon and annotations used in the data. In this blog post, we\u0026rsquo;ll provide a beginner-friendly tutorial to the BraTS 2018 dataset, designed to help you get up to speed with the basics of brain imaging and understand the annotations used in the data.\nJargon explanation Before diving deep into the details, let us familiarize ourselves with the jargon.\nNecrosis is the death of cells or tissues in the body, and in the context of BraTS data, it refers to the death of brain tissue, which can be caused by various factors such as injury, disease, or lack of oxygen. Peritumoral edematous/invaded tissue refers to the tissue surrounding a brain tumor that has become swollen or infiltrated by the tumor. Edema is a condition in which fluid accumulates in the tissue, causing swelling, and can be a result of various factors, including inflammation, injury, or disease. Peritumoral means around the tumor. In the context of glioblastoma brain tumors, low-grade tumors (LGG) are characterized by slower growth and less aggressive behavior, while high-grade tumors (HGG) are characterized by faster growth and more aggressive behavior. The grade of glioblastoma is determined by the appearance of the tumor cells under a microscope and is used to predict the behavior of the tumor and guide treatment decisions. Low-grade glioblastomas are generally considered to have a better prognosis than high-grade glioblastomas, which are more likely to grow and spread rapidly, making them more difficult to treat. It is important to note that the grade of glioblastoma can change over time, and regular monitoring and re-biopsy may be necessary to determine the current grade of the tumor. The default view provided in the papers are using the axial slices. There are 3 kind of slices: Fig. 1. Anatomical planes Data descriptions Pre-operative MRI scans from multiple institutions that are multimodal, including: Native (T1) Post-contrast T1-weighted (T1Gd) T2-Weighted (T2) T2 Fluid Attenuated Inversion Recovery (FLAIR) Annotations for the following sub-regions: GD-enhancing tumors (ET, 4) Peritumoral edema (ED, 2) Necrotic and non-enhancing tumor (NCR/NET, 1) Data that has been pre-processed, including: Co-registration to the same anatomical template Interpolation to the same resolution (1mm^3) Skull-stripping The dataset was obtained from 19 institutions. Participants are allowed to use additional private data from their own institutions for data augmentation. Compared to BraTS16 and sooner More routine 3T multimodal MRI scans that are significantly different from previous collections. All scans from the original TCIA (The Cancer Imaging Archive) glioma collections were radiologically assessed and categorized as pre- or post-operative. Experts annotated all pre-operative TCIA scans for the various sub-regions. This year, expert neuroradiologists evaluated the entire original TCIA glioma collections (TCGA-GBM, n=262 and TCGA-LGG, n=199). Each scan was categorized as pre- or post-operative, and all pre-operative TCIA scans (135 GBM and 108 LGG) were annotated by experts for the various glioma sub-regions. The annotated pre-operative scans were included in this year\u0026rsquo;s BraTS datasets. Evaluation framework Manual segmentation labels of tumor sub-regions. Dice score, Hausdorff distance, sensitivity, specificity. BraTS12-13 are subsets of BraTS18, and people also calculate on these datasets, to compare with performances reported in the BraTS TMI. First place approach: 3D MRI brain tumor segmentation using autoencoder regularization. Clinical data of overall survival. Brain imaging modalities quick comparison Brain imaging modalities can help visualize different aspects of the brain and its tissues. The following are common MRI imaging techniques used for brain imaging, each providing different information about the brain:\nT1-weighted scan (T1Gd): This type of MRI scan is performed after the administration of a contrast agent (Gadolinium for examples) and highlights areas of abnormal tissue. It enhances the visibility of certain structures, such as tumors and blood vessels. T2-weighted scan (T2): This type of MRI scan visualizes the brain\u0026rsquo;s white matter and fluid-filled spaces. It helps to identify conditions such as hydrocephalus, brain swelling, and multiple sclerosis. T2 Fluid Attenuated Inversion Recovery (T2-FLAIR): This type of MRI scan visualizes the brain\u0026rsquo;s white matter and fluid-filled spaces. It is performed after the application of a specific pulse sequence that helps to suppress the signal from cerebrospinal fluid, making it easier to visualize lesions and other abnormalities in the white matter. ⇒ It is common to use a combination of these scans to get a more complete picture of the brain and its structures. More information about brain imaging modalities can be found at this link.\nHow to differentiate between MRI brain modalities? Fig. 2. Common brain MRI modalities: T1-weighted, T2-weighted, and T2-FLAIR Legends: - X: Cerebrospinal fluid (CSF) - Triangle: White matter (WM) (Inside / Near CSF) - Square: Gray matter (GM) (Outside / Far from CSF) To differentiate between MRI brain modalities, follow these steps: Choose axial slices of the MRI scan whose CSF is visible. Locate WM and GM: WM is located on top of the CSF GM is near the skull/brain border Determine the color of CSF: CSF is white → T2-weighted CSF is black → T1-weighted (aka T1Gd) or T2-FLAIR Determine the WM and GM colors: If they follow the logical sense (GM is gray and WM is white) or if WM is brighter than GM → T1. If they do not follow the logical sense → T2-FLAIR. If you are still unclear, make sure to checkout these two Youtube videos: Video1 and Video2.\nAnnotations and Structures Fig. 3. An example taken from the BraTS 2014-15 data, showing different kind of glioma sub-regions. From left to right:\nThe whole tumor (yellow) visible in T2-FLAIR (A) The tumor core (red) visible in T2 (B) The active tumor structures (light blue) visible in T1Gd, surrounding the cystic/necrotic components of the core (green) (C) The segmentations are combined to generate the final labels of the tumor sub-regions (D): ED (yellow), NET (red), NCR cores (green), AT (blue) Labeled regions Necrotic (NCR) and Non-Enhancing Tumor Core (NET, Label 1) Typically hypo-intense (darker) in T1Gd when compared to T1. NET has been merged with NCR (Label 1) to represent non-enhancing tumor regions, transitional/pre-necrotic, and necrotic regions that belong to the non-enhancing part of the TC, and are typically resected in addition to the AT. Peritumoral Edematous/Invaded Tissue (ED, Label 2) Hyper-intense signal in T2-FLAIR, which includes the complete extent of the disease, including the TC and ED. Active Tumor (AT) aka Enhancing Tumor (ET, Label 4) Biologically, AT represents regions where there is leakage of contrast through a disrupted blood-brain barrier, commonly seen in HGG. To delineate the AT in gliomas, it is recommended to use the T1Gd scans and the existing TC outline. Set an intensity threshold within this label to distinguish between the high-intensity AT and the low-intensity NET/NCR regions. Choroid plexus and hemorrhage areas should not be labeled as they can be identified by comparing them to the T1 scan. Tumor sub-regions for evaluation: Whole Tumor (WT) Visible in T2-FLAIR: this sub-region represents the complete extent of the disease, including the tumor core (TC) and the peritumoral edematous/invaded tissue (ED). It is the union of all available labels and is usually the largest with a relatively smooth shape. Manual delineations can be made every third slice. Tumor Core (TC) Visible in T2: this sub-region includes the bulk of the tumor that is typically removed during surgery. It is the union of labels 1, 3 (unlabeled, merged with 1), and 4. Non-enhancing tumor regions must be checked for in this sub-region. Its boundaries can be delineated on every other slice. Once the TC boundaries are defined, the remaining WT will correspond to the ED sub-region (Label 2), which is described by a hyper-intense signal on the T2-FLAIR volumes. Active Tumor aka Enhanced Tumor (AT/ET) Visible in T1Gd: this sub-region represents the active or enhancing tumor structures surrounding the cystic/necrotic components of the core. Areas in this sub-region show hyper-intensity (brighter) in T1Gd when compared to T1 and \u0026ldquo;healthy\u0026rdquo; white matter in T1Gd. Remarks for Low Grade Gliomas (LGG) LGGs do not exhibit much contrast enhancement or peritumoral edema. LGGs have less blood-brain-barrier disruption, which results in less contrast leak during the scan. LGGs without an apparent enhancing tumor (ET) area should consider only the necrotic/non-enhancing tumor (NET) and vasogenic edema (ED) labels, by observing the texture or intensity on T2-FLAIR images. LGGs without ET and without obvious differences across modalities should consider only the NET label, distinguishing between normal and abnormal brain tissue. Deducing segmentations takeaway points This is what the papers recommended: Start by delineating the sub-regions of interest from the outside tumor boundaries. In other words, begin with manual delineation of the abnormal signal in the T2-weighted images. Define the Whole Tumor (WT) and then address the Tumor Core (TC), including enhancing/non-enhancing/necrotic core. In more details, here are the steps and explanations: Start with inspecting the T2-FLAIR → Hyper-intense regions (Bright) are ED (Label 2). Most of the time, ED are the outer boundaries of the Whole Tumor (WT). Since we have no Tumor Core (TC) ground truth, we will define it using its definition: the union of NCR/NET (Label 1, 3) and AT/ET (Label 4). We delineate the NCR/NET (Label 1, 3) and AT/ET at the same time using T1Gd, where: NCR/NET are hypo-intense (darker) regions (Also true when comparing to T1) AT/ET are hyper-intense (brighter) regions, most of the time encircling NCR/NET. (Also true when comparing to T1) These two regions appear together with significant contrast in T1Gd. The axial slices of T2 can either be used to: Refine the union of Label 1, 3, and 4 when delineate the TC using T1Gd. Pre-determine the outline of TC. ⇒ By following these steps, you can obtain both Label 1, 3, and 4 so that you can union them all and get TC.\nI hope you enjoy reading. If you want to learn more about the brain\u0026rsquo;s anatomy, I recommend visiting this site, which has fantastic visualizations. I sometimes update old posts to keep them up-to-date.\nReferences Bakas, Spyridon, et al 2018 International MICCAI BraTS Challenge - CBICA MICCAI 2018. Bakas, Spyridon, et al Multimodal Brain Tumor Segmentation Challenge 2018 Section for Biomedical Image Analysis (SBIA) (2021). Bakas, Spyridon, et al Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation, Progression Assessment, and Overall Survival Prediction in the BRATS Challenge arXiv preprint arXiv:1811.02629 (2018). Bjoern H. Menze et al he Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) IEEE Transactions on Medical Imaging (2015). ","permalink":"https://louisdo2108.github.io/posts/brats2018/brats2018/","summary":"Brain tumor segmentation is a critical task in medical image analysis, and the BraTS (Brain Tumor Segmentation) challenge dataset is one of the most widely used benchmarks in the field. However, getting started with brain imaging can be intimidating, especially if you\u0026rsquo;re not familiar with the complex medical jargon and annotations used in the data. In this blog post, we\u0026rsquo;ll provide a beginner-friendly tutorial to the BraTS 2018 dataset, designed to help you get up to speed with the basics of brain imaging and understand the annotations used in the data.","title":"BraTS 2018"},{"content":" Probably not me but I like it Tuan-Luc Huynh Information Technology Faculty, Vietnam National University, Ho Chi Minh City University of Science EDUCATION VNUHCM - University of Science, Ho Chi Minh City, Vietnam (Aug 2019 - present) B.S. in Computer Science, GPA: 3.95/4. Thesis topic: Efficient Brain Tumor Segmentation using nnUNet. RESEARCH EXPERIENCE Research Assistant, Software Engineering Laboratory (SELAB), Information Technology Faculty, Vietnam National University, Ho Chi Minh City University of Science (Oct 2022 - Present) Perform research-related tasks and assist with ongoing projects. Participate in international workshops and collaborate with other researchers. WORK EXPERIENCE Data Scientist Intern, The Center of Applied Data Science (CADS), FPT Telecom (Feb 2022 - Sep 2022) Project: Potential smartphone customers modeling using transaction data. Conducted exploratory data analysis (EDA), data wrangling, and feature engineering on tabular data. Developed and fine-tuned models using AutoML frameworks. SKILLS Programming languages: Python, C++, C, C#, Java, R. Tech \u0026amp; Tools: PyTorch, LaTeX, scikit-learn, Optuna, PyCaret, Slurm, Markdown, HTML, CSS, Apache Hadoop, Overleaf, Notion, Excel, PowerPoint, Mendeley, Slicer, Generative Models, Large Language Models. Hands-on experience in Data Science using AutoML and deep learning frameworks. PUBLICATIONS Thao Thi Phuong Dao, Tuan-Luc Huynh, Minh-Khoi Pham, Trung-Nghia Le Le, Tan-Cong Nguyen, Quang-Thuc Nguyen, Bich Anh Tran, Boi Ngoc Van, Chanh Cong Ha, and Minh-Triet Tran, \u0026quot;Improving Laryngoscopy Image Analysis through Integration of Global Information and Local Features in VoFoCD Dataset\u0026quot;. Co-first author; Submitting to Computers in Biology and Medicine, IF: 6.698\nTrung-Nghia Le, Tam V Nguyen, Minh-Quan Le, Trong-Thuan Nguyen, Viet-Tham Huynh, Trong-Le Do, Khanh-Duy Le, Mai-Khiem Tran, Nhat Hoang-Xuan, Thang-Long Nguyen-Ho, Tuan-Luc Huynh, et al. \u0026quot;SketchANIMAR: Sketch-based 3D Animal Fine-Grained Retrieval\u0026quot;, arXiv preprint arXiv:2304.05731, 2023.\nTuan-Luc Huynh, Nguyen-Ngoc Khoi-Nguyen, Chi-Bien Chu, Minh-Triet Tran, Trung-Nghia Le, \u0026quot;Multilingual Communication System with Deaf Individuals Utilizing Natural and Visual Languages\u0026quot;. In 2022 RIVF International Conference on Computing and Communication Technologies (RIVF), pp. 683-688, 2022, IEEE.\nJie Qin, Shuaihang Yuan, Jiaxin Chen, Boulbaba Ben Amor, Yi Fang, Nhat Hoang-Xuan, Chi-Bien Chu, Khoi-Nguyen Nguyen-Ngoc, Thien-Tri Cao, Nhat-Khang Ngo, Tuan-Luc Huynh, and others, \u0026quot;SHREC’22 track: Sketch-based 3D shape retrieval in the wild\u0026quot;, Computers \u0026amp; Graphics, vol. 107, pp. 104-115, 2022, Elsevier.\nTuan-Luc Huynh, Nhat-Khang Ngo, Phu-Van Nguyen, Thien-Tri Cao, Thanh-Danh Le, Hai-Dang Nguyen, Minh-Triet Tran, \u0026quot;HCMUS at MediaEval2021: Content-Based Misinformation Detection Using Contextualized Word Embedding from BERT\u0026quot;. In Working Notes Proceedings of the MediaEval 2021 Workshop, Online, vol. 3181, 2021. -Thien-Tri Cao, Nhat-Khang Ngo, Thanh-Danh Le, Tuan-Luc Huynh, Ngoc-Thien Nguyen, Hai-Dang Nguyen, Minh-Triet Tran, \u0026quot;HCMUS at MediaEval 2021: Fine-tuning CLIP for Automatic News-Images Re-Matching\u0026quot;. In Working Notes Proceedings of the MediaEval 2021 Workshop, Online, vol. 3181, 2021.\nNhat-Khang Ngo, Tuan-Luc Huynh, Thanh-Danh Le, Hai-Dang Nguyen, and Minh-Triet Tran, \u0026quot;HCMUS at MediaEval2021: Polyps Segmentation using TransFuse with Focal Tversky Loss\u0026quot;. In Working Notes Proceedings of the MediaEval 2021 Workshop, Online, vol. 3181, 2021.\nRESEARCH INTERESTS Machine Learning Deep Learning Computer Vision Self-Supervised Learning Medical Image Computing ACADEMIA SERVICE Mar 2023: Co-organizers of MediaEval 2023 Medical Multimedia Task AWARDS \u0026amp; ACHIEVEMENTS 2023\nAchieved 2nd place in the Sketch-based 3D Animal Fine-Grained Retrieval Challenge at SHREC 2023. Received a Distinctive Mention from the organizers of the Medico Medical Multimedia task in MediaEval 2022. 2022\nAwarded the Academic Excellence Award from the University of Science for the academic year 2021-2022, ranking among the top five students with the highest GPA in the Advanced Program in Computer Science. Received a Full-tuition scholarship from the University of Science for the academic year 2021-2022. Received a Certificate of Merit from the President of Vietnam National University Ho Chi Minh City for outstanding achievements in scientific research during the academic year 2021-2022. Received a Certificate of Merit from the Principal of Ho Chi Minh City University of Sciences for outstanding achievements in scientific research during term II of the academic year 2021-2022. 2021\nAchieved 1st place in the NewsImage task and 2nd place in the FakeNews task at MediaEval 2021. MAIN COURSES Data Structures Introduction to Database Systems Applied Statistics for Engineers and Scientists Artificial Intelligence Algorithms and Complexity Machine Learning Introduction to Natural Language Processing Computer Vision Introduction to Big Data Analytics Information Retrieval LANGUAGES Vietnamese (Native, Bilingual) Cantonese (Native, Bilingual) English (Fully Professional, IELTS 6.0 (Minimum requirement, test will be taken in July 2023)) Mandarin (Fully Professional, HSK6 238/300 (2018)) HOBBY Travelling Landscape photograph Brewing coffee and tea Reading manga Listening to music Video games You can download my full CV here.\n","permalink":"https://louisdo2108.github.io/about/","summary":"about","title":"About Tuan-Luc Huynh (Louis Do)"},{"content":"Introduction This is my first post.\n","permalink":"https://louisdo2108.github.io/posts/hugo_test/my-first-post/","summary":"Introduction This is my first post.","title":"My First Post"},{"content":"","permalink":"https://louisdo2108.github.io/tags/","summary":"tags","title":"Tags"}]